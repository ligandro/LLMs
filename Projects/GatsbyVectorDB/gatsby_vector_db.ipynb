{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32589371",
   "metadata": {},
   "source": [
    "# ðŸ“š The Great Gatsby - Vector Database Project\n",
    "\n",
    "This notebook demonstrates how to convert F. Scott Fitzgerald's \"The Great Gatsby\" into a searchable vector database using ChromaDB and perform semantic search queries.\n",
    "\n",
    "## What You'll Learn:\n",
    "- Loading and preprocessing text data\n",
    "- Creating embeddings with SentenceTransformers\n",
    "- Storing vectors in ChromaDB\n",
    "- Performing semantic search queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4833b4",
   "metadata": {},
   "source": [
    "## 1. Install and Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05539d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install chromadb sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dba698",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eca4c74",
   "metadata": {},
   "source": [
    "## 2. Download The Great Gatsby Text\n",
    "\n",
    "We'll download the text from Project Gutenberg (public domain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cb0ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download The Great Gatsby from Project Gutenberg\n",
    "url = \"https://www.gutenberg.org/files/64317/64317-0.txt\"\n",
    "data_path = Path(\"data/great_gatsby.txt\")\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "data_path.parent.mkdir(exist_ok=True)\n",
    "\n",
    "# Download the file if it doesn't exist\n",
    "if not data_path.exists():\n",
    "    print(\"ðŸ“¥ Downloading The Great Gatsby...\")\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    with open(data_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(response.text)\n",
    "    print(\"âœ… Downloaded successfully!\")\n",
    "else:\n",
    "    print(\"âœ… File already exists!\")\n",
    "\n",
    "# Read the file\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(f\"ðŸ“Š Total characters: {len(raw_text)}\")\n",
    "print(f\"ðŸ“Š First 500 characters:\\n{raw_text[:500]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0b2fa1",
   "metadata": {},
   "source": [
    "## 3. Clean and Preprocess the Text\n",
    "\n",
    "Remove Project Gutenberg headers/footers and clean the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556de7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the text - remove Project Gutenberg header and footer\n",
    "def clean_text(text):\n",
    "    # Find the start of the actual book (after the Gutenberg header)\n",
    "    start_markers = [\"CHAPTER I\", \"Chapter I\", \"CHAPTER 1\"]\n",
    "    start_idx = 0\n",
    "    for marker in start_markers:\n",
    "        idx = text.find(marker)\n",
    "        if idx != -1:\n",
    "            start_idx = idx\n",
    "            break\n",
    "    \n",
    "    # Find the end (before Gutenberg footer)\n",
    "    end_markers = [\"End of Project Gutenberg\", \"*** END OF THE PROJECT GUTENBERG\"]\n",
    "    end_idx = len(text)\n",
    "    for marker in end_markers:\n",
    "        idx = text.find(marker)\n",
    "        if idx != -1:\n",
    "            end_idx = idx\n",
    "            break\n",
    "    \n",
    "    # Extract the main text\n",
    "    clean = text[start_idx:end_idx]\n",
    "    \n",
    "    # Clean up extra whitespace\n",
    "    clean = re.sub(r'\\n{3,}', '\\n\\n', clean)\n",
    "    clean = re.sub(r' {2,}', ' ', clean)\n",
    "    \n",
    "    return clean.strip()\n",
    "\n",
    "cleaned_text = clean_text(raw_text)\n",
    "print(f\"ðŸ“Š Cleaned text length: {len(cleaned_text)} characters\")\n",
    "print(f\"ðŸ“Š First 500 characters:\\n{cleaned_text[:500]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b61ce8",
   "metadata": {},
   "source": [
    "## 4. Split Text into Chunks\n",
    "\n",
    "We'll split the text into paragraphs for better semantic search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e28a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into paragraphs (chunks)\n",
    "def split_into_chunks(text, min_length=100):\n",
    "    \"\"\"Split text into paragraphs, filtering out very short ones.\"\"\"\n",
    "    # Split by double newlines (paragraphs)\n",
    "    paragraphs = text.split('\\n\\n')\n",
    "    \n",
    "    # Filter out very short paragraphs\n",
    "    chunks = [p.strip() for p in paragraphs if len(p.strip()) >= min_length]\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "chunks = split_into_chunks(cleaned_text)\n",
    "print(f\"ðŸ“Š Number of chunks: {len(chunks)}\")\n",
    "print(f\"ðŸ“Š Average chunk length: {sum(len(c) for c in chunks) // len(chunks)} characters\")\n",
    "print(f\"\\nðŸ“ Sample chunk (first one):\\n{chunks[0][:300]}...\")\n",
    "print(f\"\\nðŸ“ Sample chunk (middle one):\\n{chunks[len(chunks)//2][:300]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ccaa01",
   "metadata": {},
   "source": [
    "## 5. Initialize ChromaDB Client\n",
    "\n",
    "Create a persistent client to store our vector database locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c0501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ChromaDB with persistent storage\n",
    "chroma_client = chromadb.PersistentClient(path=\"./gatsby_vector_db\")\n",
    "print(\"âœ… ChromaDB client initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f2ed9a",
   "metadata": {},
   "source": [
    "## 6. Create Sentence Transformer Embedding Function\n",
    "\n",
    "Initialize the embedding model using SentenceTransformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575cbe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding function using SentenceTransformer\n",
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Sentence Transformer embedding function created!\")\n",
    "print(\"ðŸ“Š This model creates 384-dimensional embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e13a47",
   "metadata": {},
   "source": [
    "## 7. Create Vector Embeddings\n",
    "\n",
    "Generate embeddings for all text chunks. This may take a minute..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac70002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for all chunks\n",
    "print(f\"ðŸ”„ Generating embeddings for {len(chunks)} chunks...\")\n",
    "vectors = sentence_transformer_ef(chunks)\n",
    "\n",
    "print(f\"âœ… Generated {len(vectors)} embeddings!\")\n",
    "print(f\"ðŸ“Š Each embedding has {len(vectors[0])} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f24e44",
   "metadata": {},
   "source": [
    "## 8. Store Embeddings in ChromaDB Collection\n",
    "\n",
    "Create a collection and add all chunks with their embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02bf267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique IDs for each chunk\n",
    "ids = [f\"chunk_{i}\" for i in range(len(chunks))]\n",
    "\n",
    "# Uncomment to delete existing collection if needed\n",
    "# chroma_client.delete_collection(name=\"great_gatsby\")\n",
    "\n",
    "# Create or get collection\n",
    "collection = chroma_client.get_or_create_collection(name=\"great_gatsby\")\n",
    "\n",
    "print(f\"ðŸ“¦ Adding {len(chunks)} chunks to ChromaDB...\")\n",
    "\n",
    "# Add documents to collection\n",
    "collection.add(\n",
    "    documents=chunks,\n",
    "    ids=ids,\n",
    "    embeddings=vectors,\n",
    ")\n",
    "\n",
    "print(f\"âœ… Successfully added documents to collection!\")\n",
    "print(f\"ðŸ“Š Collection count: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5ead21",
   "metadata": {},
   "source": [
    "## 9. Query the Vector Database\n",
    "\n",
    "Now let's search for relevant passages using semantic search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e6f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 1: Find passages about Gatsby's parties\n",
    "query = \"Gatsby's extravagant parties with music and dancing\"\n",
    "query_embedding = sentence_transformer_ef([query])\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=query_embedding,\n",
    "    n_results=5, # how many results to return\n",
    ")\n",
    "\n",
    "print(\"ðŸ” Query:\", query)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "for i, (doc, distance) in enumerate(zip(results['documents'][0], results['distances'][0])):\n",
    "    print(f\"\\nðŸ“„ Result {i+1} (Similarity: {1-distance:.4f})\")\n",
    "    print(\"-\" * 80)\n",
    "    print(doc[:300] + \"...\" if len(doc) > 300 else doc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c225b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 2: Find passages about the green light\n",
    "query = \"the green light at the end of the dock\"\n",
    "query_embedding = sentence_transformer_ef([query])\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=query_embedding,\n",
    "    n_results=3,\n",
    ")\n",
    "\n",
    "print(\"ðŸ” Query:\", query)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "for i, (doc, distance) in enumerate(zip(results['documents'][0], results['distances'][0])):\n",
    "    print(f\"\\nðŸ“„ Result {i+1} (Similarity: {1-distance:.4f})\")\n",
    "    print(\"-\" * 80)\n",
    "    print(doc[:400] + \"...\" if len(doc) > 400 else doc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982c2c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query 3: Find passages about Daisy and Tom\n",
    "query = \"Daisy and Tom Buchanan relationship\"\n",
    "query_embedding = sentence_transformer_ef([query])\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=query_embedding,\n",
    "    n_results=3,\n",
    ")\n",
    "\n",
    "print(\"ðŸ” Query:\", query)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "for i, (doc, distance) in enumerate(zip(results['documents'][0], results['distances'][0])):\n",
    "    print(f\"\\nðŸ“„ Result {i+1} (Similarity: {1-distance:.4f})\")\n",
    "    print(\"-\" * 80)\n",
    "    print(doc[:400] + \"...\" if len(doc) > 400 else doc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b60c580",
   "metadata": {},
   "source": [
    "## 10. Try Your Own Queries!\n",
    "\n",
    "Modify the query below to search for any topic in The Great Gatsby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d641702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ Try your own query here!\n",
    "# Suggestions: \"Nick Carraway narrator\", \"valley of ashes\", \"Jordan Baker golf\", \n",
    "#              \"Gatsby's past\", \"car accident\", \"eyes of Doctor T.J. Eckleburg\"\n",
    "\n",
    "query = \"eyes of Doctor T.J. Eckleburg watching over everything\"\n",
    "query_embedding = sentence_transformer_ef([query])\n",
    "\n",
    "results = collection.query(\n",
    "    query_embeddings=query_embedding,\n",
    "    n_results=5,\n",
    ")\n",
    "\n",
    "print(\"ðŸ” Query:\", query)\n",
    "print(f\"\\nðŸ“Š Found {len(results['documents'][0])} results\\n\")\n",
    "print(\"=\"*80)\n",
    "for i, (doc, distance) in enumerate(zip(results['documents'][0], results['distances'][0])):\n",
    "    print(f\"\\nðŸ“„ Result {i+1} (Similarity: {1-distance:.4f})\")\n",
    "    print(\"-\" * 80)\n",
    "    print(doc[:350] + \"...\" if len(doc) > 350 else doc)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b84e08",
   "metadata": {},
   "source": [
    "## 11. Alternative Query Method\n",
    "\n",
    "You can also use `query_texts` instead of creating embeddings manually. ChromaDB will create embeddings automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c350a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative method - let ChromaDB handle the embedding\n",
    "results = collection.query(\n",
    "    query_texts=[\"Gatsby's mysterious wealth and background\"],\n",
    "    n_results=3,\n",
    ")\n",
    "\n",
    "pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896faa70",
   "metadata": {},
   "source": [
    "## 12. Database Statistics\n",
    "\n",
    "Let's check the statistics of our vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2a9068",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“Š Vector Database Statistics\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Collection Name: {collection.name}\")\n",
    "print(f\"Total Documents: {collection.count()}\")\n",
    "print(f\"Embedding Dimensions: 384\")\n",
    "print(f\"Embedding Model: all-MiniLM-L6-v2\")\n",
    "print(f\"Storage Path: ./gatsby_vector_db\")\n",
    "print(\"\\nâœ… The Great Gatsby is now fully searchable as a vector database!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
